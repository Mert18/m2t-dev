---
title: Learning Kubernetes, Part 1
description: Learning Kubernetes, but only what it is and how it works for now.
date: August, 22th. 2023
category: learning,cloud
kind: aitalk
---

<Prompt>
  <p>
    I want to learn what Kubernetes is. I have heard of it many times, but it is
    just a fuzzy knowledge that I have. First of all, I want to start from the
    beginning. Kubernetes and Cloud are two words that is used always together.
    What is "Cloud"? Is it really just "someone else's computer"?
  </p>
</Prompt>

<AIResponse>
  <p>
    Yes, the phrase "someone else's computer" is often used humorously to
    describe the concept of cloud computing, but there's more to it than that.
    Cloud computing is a technology that involves delivering various computing
    services—such as storage, processing power, databases, networking, and
    more—over the internet. Instead of owning and maintaining physical hardware
    and infrastructure, users can access these resources on-demand from cloud
    service providers.
  </p>
</AIResponse>

<Prompt>
  <p>
    I understand, and how it is related to Kubernetes? Do not respond too long,
    write only paragraphs and do not be formal, act like we are talking face to
    face. It's better if you give real life analogies.
  </p>
</Prompt>

<AIResponse>
  <p>
    Sure thing! Imagine Kubernetes as a superstar manager for your app
    containers. You know, those containers are like portable boxes that hold
    everything your app needs to run smoothly. Well, Kubernetes takes care of
    moving these containers around, making sure they're working fine, and even
    helping them party with each other.
  </p>
  <br />
  <p>
    Think of it as a fancy party planner. You tell the planner what kind of
    party you want, and they make sure everything happens smoothly. In this
    case, you tell Kubernetes how you want your app to run, and it takes care of
    the nitty-gritty details, like where to put containers, how many to have,
    and even swapping out old ones for fresh versions without causing any chaos.
  </p>
  <br />
  <p>
    Now, the "cloud" part is like renting a magical party space instead of
    hosting the party at your own place. It's like throwing a bash at a super
    cool venue where they handle all the setup, clean-up, and even provide extra
    stuff you might need. Similarly, cloud computing means using services and
    resources from big tech companies (like Amazon, Google, or Microsoft) to
    host your apps and data. Kubernetes plays really well with the cloud,
    because it helps manage your app's containers no matter where they're
    partying – whether in a local data center or on the cloud's "dance floor."
  </p>
</AIResponse>

<Prompt>
  <p>
    I see, now let's say I have an application and somehow containerized it and
    can be pulled from docker hub. What are the steps to run my application on
    Kubernetes? Do not give too many details, just talk about the process.
  </p>
</Prompt>

<AIResponse>
  <p>
    Absolutely, I'll break it down in a nutshell! To get your containerized app
    grooving on Kubernetes:
  </p>
  <br />
  <p>
    <b>Set Up Kubernetes Cluster</b>: First, you need a Kubernetes cluster. This
    is like preparing the dance floor. It can be on your own hardware or using a
    cloud provider's service.
  </p>
  <br />
  <p>
    <b>Define Configs</b>: Create configuration files that describe how you want
    your app to run on Kubernetes. This includes things like how many containers
    you need, what resources they should use, and how they should talk to each
    other.
  </p>
  <br />
  <p>
    <b>Apply Configs</b>: Use the Kubernetes command-line tools to apply those
    configs to your cluster. It's like giving the DJ your playlist – Kubernetes
    now knows what to do.
  </p>
  <br />
  <p>
    <b>Kubernetes Does Magic</b>: Once you apply those configs, Kubernetes takes
    over. It brings up your app's containers, distributes them, and ensures
    they're working smoothly. It's like the party planner making sure
    everything's in place.
  </p>
  <br />
  <p>
    <b>Monitor and Tweak</b>: Keep an eye on things. If you want to change
    something – like adding more containers when the dance floor gets crowded –
    you can tweak the configs and let Kubernetes handle the adjustments.
  </p>
  <br />
  <p>
    <b>Celebrate Updates</b>: When you have a new version of your app, just
    update the config files. Kubernetes will smoothly roll out the changes,
    making sure your app is updated without crashing the party.
  </p>
  <br />
  <p>
    It's like setting up a party, handing the plans to the event manager
    (Kubernetes), and letting them handle the details while you enjoy the
    festivities!
  </p>
</AIResponse>

<Prompt>
  <p>
    In the second step, you mentioned "configs". What types of configs there
    are? Can you elaborate?
  </p>
</Prompt>

<AIResponse>
  <p>
    Absolutely, let's dive into those configs a bit more. In the Kubernetes
    world, these configuration files are usually written in YAML format. They
    tell Kubernetes how to run and manage your app. Here are some key types of
    configs you'll work with:
  </p>
  <br />
  <p>
    <b>Pods</b>: Pods are like the smallest units in Kubernetes. They can
    contain one or more containers that work closely together. In the config,
    you specify which container images to use, any environment variables, ports
    to expose, and more.
  </p>
  <br />
  <p>
    <b>Deployments</b>: Deployments handle managing the desired number of pods
    and ensuring they're always up and running. You define how many replicas
    (copies) of your pods you want, what updates to apply, and other scaling
    behaviors.
  </p>
  <br />
  <p>
    <b>Services</b>: Services provide a consistent way for your pods to
    communicate, even if they're on different nodes or get replaced. They can
    expose your app inside the cluster (ClusterIP), make it accessible
    externally (NodePort or LoadBalancer), or even do some clever routing
    (Ingress).
  </p>
  <br />
  <p>
    <b>ConfigMaps and Secrets</b>: These let you separate your app's
    configuration and sensitive info (like passwords) from your code. You can
    store them outside your container images, making updates easier.
  </p>
  <br />
  <p>
    <b>Persistent Volumes and Claims</b>: If your app needs storage that
    survives even if pods come and go, you use these. They're like renting a
    storage locker that stays even if you change apartments.
  </p>
  <br />
  <p>
    <b>Namespace</b>: Think of it as creating separate dance floors within the
    same club. It helps organize and separate different projects, teams, or apps
    within your Kubernetes cluster.
  </p>
  <br />
  <p>
    <b>Ingress</b>: If you're exposing your app to the outside world, Ingress
    lets you manage external access and routing, like directing traffic to the
    right pods based on URL paths.
  </p>
  <br />
  <p>
    <b>Jobs and CronJobs</b>: For tasks that need to run once (Job) or on a
    schedule (CronJob), these configs help manage that. Think of them as getting
    the cleaning crew to tidy up the dance floor after the party.
  </p>
</AIResponse>

<Prompt>
  <p>
    Okay, everything is a bit more clear now. But you mentioned "nodes" in
    kubernetes. Can I think of them as different "virtual machines" in a
    "physical machine"? How are they isolated?
  </p>
</Prompt>

<AIResponse>
  <p>
    You're on the right track! Nodes in Kubernetes can be thought of as
    individual "virtual machines" within a "physical machine," but there's a bit
    more to it. Here's the breakdown:
  </p>
  <br />
  <p>
    <b>Nodes as Virtual Machines</b>: In a sense, yes. Nodes are like the
    individual computers within your cluster. They're responsible for running
    your containers. Just like you'd run multiple virtual machines on a single
    physical server, you can run multiple nodes on a single physical machine.
  </p>
  <br />
  <p>
    <b>Isolation</b>: Kubernetes uses container technology (usually Docker or
    similar) for isolation. Containers are like lightweight virtual machines,
    but they share the same operating system kernel. They're isolated enough to
    prevent conflicts between different apps running on the same node.
    Containers on a node can't directly mess with each other's stuff.
  </p>
  <br />
  <p>
    <b>Node Roles</b>: Nodes can take on different roles. You have "worker
    nodes" that run your app's containers, and you also have a "master node"
    that manages the cluster's overall state, like orchestrating deployments,
    scaling, and distributing workloads.
  </p>
  <br />
  <p>
    <b>Pods as Units of Work</b>: The smallest unit in Kubernetes is the pod,
    and it's like a wrapper around one or more containers. Containers within the
    same pod share the same network and storage space. This is where isolation
    comes into play. Containers within the same pod can communicate easily, and
    Kubernetes makes sure they're on the same node.
  </p>
  <br />
  <p>
    <b>Node-Level Isolation</b>: Kubernetes ensures that different pods from
    different apps, even on the same node, are isolated from each other. They
    have their own IP addresses, ports, file systems, and processes. If a pod
    misbehaves, it doesn't affect other pods on the same node.
  </p>
  <br />
  <p>
    So, while nodes are indeed somewhat like virtual machines within a physical
    machine, the containerization technology and Kubernetes' management keep
    things neatly isolated and organized, preventing party crashers and ensuring
    each app can dance freely on its designated node.
  </p>
</AIResponse>

<Prompt>
  <p>
    If nodes in kubernetes are completely isolated, why we usually deploy 3
    worker node and 1 master in a typical deployment pattern? I mean, if our
    resources will work on one node, why do we have 3?
  </p>
</Prompt>

<AIResponse>
  <p>
    So, think of Kubernetes like a team sport – you want backup players on the
    bench, right? Having multiple worker nodes in a cluster adds a layer of
    redundancy and fault tolerance. If one node decides to take a coffee break
    or, worse, crashes unexpectedly, the other nodes can pick up the slack. It's
    like having teammates ready to step in when needed.
  </p>
  <p>
    Also, spreading the workload across nodes can improve performance. It's like
    not putting all your eggs in one basket – tasks can be divided and
    conquered, which helps with resource management and overall efficiency.
  </p>
  <p>
    So, yeah, having this setup might seem like overkill at first, but it's all
    about keeping your Kubernetes ship sailing even when some waves get rough!
  </p>
</AIResponse>

<Prompt>
  <p>
    Okay, that's enough for part 1, in the next section, let's deploy an app
    together!
  </p>
</Prompt>

<AIResponse>
  <p>
    Absolutely, let's dive into some hands-on fun! Imagine we're at a coding
    café, ready to cook up some code. So, what's the app you're thinking of? A
    sizzling web app? A cool API? Spill the beans, and we'll whip it up together
    step by step! 🚀
  </p>
</AIResponse>
